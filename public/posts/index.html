<!DOCTYPE html>
<html lang="en" dir="auto" data-theme="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="noindex, nofollow">
<title>Posts | Thinking in Agents</title>
<meta name="keywords" content="">
<meta name="description" content="Posts - Thinking in Agents">
<meta name="author" content="">
<link rel="canonical" href="http://localhost:1313/posts/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.343cc480b9ffc8f04ccbe5e968ad674880cab773ec19905e93033065c1e7a804.css" integrity="sha256-NDzEgLn/yPBMy&#43;XpaK1nSIDKt3PsGZBekwMwZcHnqAQ=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:1313/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" type="application/rss+xml" href="http://localhost:1313/posts/index.xml" title="rss">
<link rel="alternate" hreflang="en" href="http://localhost:1313/posts/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
                color-scheme: dark;
            }

            .list {
                background: var(--theme);
            }

            .toc {
                background: var(--entry);
            }
        }

        @media (prefers-color-scheme: light) {
            .list::-webkit-scrollbar-thumb {
                border-color: var(--code-bg);
            }
        }

    </style>
</noscript>
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.querySelector("html").dataset.theme = 'dark';
    } else if (localStorage.getItem("pref-theme") === "light") {
       document.querySelector("html").dataset.theme = 'light';
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.querySelector("html").dataset.theme = 'dark';
    } else {
        document.querySelector("html").dataset.theme = 'light';
    }

</script>
</head>
<body class="list" id="top">
    <header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/" accesskey="h" title="Thinking in Agents (Alt + H)">Thinking in Agents</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
        </ul>
    </nav>
</header>
<main class="main"> 
<header class="page-header">
  <h1>
    Posts
  </h1>
</header>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">AI 的未来，不在大脑，而在手：从 LLM 到工具驱动智能
      <span class="entry-hint" title="Draft">
        <svg xmlns="http://www.w3.org/2000/svg" height="20" viewBox="0 -960 960 960" fill="currentColor">
          <path
            d="M160-410v-60h300v60H160Zm0-165v-60h470v60H160Zm0-165v-60h470v60H160Zm360 580v-123l221-220q9-9 20-13t22-4q12 0 23 4.5t20 13.5l37 37q9 9 13 20t4 22q0 11-4.5 22.5T862.09-380L643-160H520Zm300-263-37-37 37 37ZM580-220h38l121-122-18-19-19-18-122 121v38Zm141-141-19-18 37 37-18-19Z" />
        </svg>
      </span>
    </h2>
  </header>
  <div class="entry-content">
    <p>在 AI 领域，我们常陷入一个误区：认为智能的未来在于构建更大、更全知、更像人脑的模型，让它记住所有知识。然而，作为开发者，我们深知这种“记忆力”的上限和局限。人类的真正智能，并非依赖于单纯的知识存储，而在于解决问题的能力。
思考我们自己解决一个复杂数学题的流程：
分析问题：理解需求。 选择工具：判断需要哪些数学工具、公式或软件。 建模与执行：运用工具进行计算、推导。 验证与决策：检查结果，修正思路，得出最终结论。 在这个过程中，最核心的不是你“背诵”了多少公式，而是你知道何时何地调用何种工具，并能高效利用它们。这是一种以“结构化思维 &#43; 目标导向”为核心的模式。
LLM 的本质与局限：语言的概率压缩器 从开发者角度看，当前的大型语言模型（LLM）本质是一个强大的语言概率压缩器。它在海量文本数据中学习词语间的统计关联，从而能生成极为流利、上下文相关的文本。对于纯语言任务，其表现令人惊叹。
然而，当我们尝试让 LLM 驾驭非语言、强逻辑、精确性的领域时，如：
抽象符号运算（数学、物理） 精确定义匹配（工程规范） 严格逻辑推导（编程、决策树） 可验证的计算过程（财务、科学实验） 我们会发现语言模型固有的“概率化”机制，与这些领域要求的“确定性”之间存在着先天鸿沟。指望 LLM 仅仅靠扩大规模来跨越这条鸿沟，就像期望一个语言学家通过背诵更多诗歌就能成为量子物理学家一样，这是不现实且低效的。
一、扩展 LLM 能力：借用人类“使用工具”的智慧 人类的进步正是通过外部工具不断突破自身生理和认知极限：计算器扩展了计算力，笔记扩展了记忆，显微镜扩展了感知，电脑扩展了逻辑运算能力。我们的大脑并非用于无限计算，而是用于调度工具、规划步骤、制定策略和验证结果。
因此，作为开发者，我们不应止步于“训练更大模型”，而应专注于赋予 LLM “使用工具”的能力。当前 AI 领域已清晰地展现了这一趋势和技术价值：
解决 LLM 算术硬伤：集成计算器工具
问题：即使是参数巨大的 LLM，在两位数以上的精确计算上依然错误频发，因为其内部知识是概率模式，而非符号计算引擎。 解决方案：通过将外部计算器作为工具接入。LLM 识别出计算任务后，不再尝试内部计算，而是将数字和运算符传递给计算器工具执行，再将准确结果整合到回复中。 价值：外部计算器提供了 LLM 内部无法比拟的精确执行能力，极大地提升了模型在数值任务上的可靠性。 克服 LLM 信息“幻觉”：引入搜索引擎与知识库工具
问题：LLM 训练数据的时效性、全面性限制，以及生成文本时为了流畅性可能出现的“编造”现象，导致其信息准确性难以保证。 解决方案：引入搜索引擎或外部知识库查询工具。LLM 在生成答案前，先调用这些工具检索最新、最准确的事实依据。例如，回答“最新诺贝尔奖得主”时，模型通过工具获取实时数据。 价值：外部工具弥补了 LLM 内部知识的盲区与时效性问题，提供了“事实校准”和“实时更新”的能力。 突破 LLM 逻辑推理瓶颈：集成代码解释器与符号系统
问题：LLM 在处理多步复杂逻辑推理、编程调试或科学问题时，往往难以保持推理链条的连贯和正确。 解决方案： 代码解释器（Code Interpreter）：LLM 生成 Python 等代码，然后将代码交给外部解释器运行验证。模型可根据运行结果（包括错误信息）进行调试和迭代。 符号推理系统：对于严谨的数学或逻辑问题，LLM 将问题转化为符号表达式，交由专门的工具处理。 价值：这些工具为 LLM 提供了其内部缺乏的精确执行和验证逻辑的能力，是其逻辑推理的强大“外挂”。 这些实践案例清晰地表明，在 AI 发展的关键阶段，尤其是面对需要超越语言模式、进行精确操作、获取实时信息和严格逻辑验证的场景时，仅仅依赖模型内部的“知识”是远远不够的。
...</p>
  </div>
  <footer class="entry-footer"><span title='2025-11-20 13:59:13 +0800 CST'>November 20, 2025</span></footer>
  <a class="entry-link" aria-label="post link to AI 的未来，不在大脑，而在手：从 LLM 到工具驱动智能" href="http://localhost:1313/posts/teaching_llm_to_use_tools/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Context Prompt-Driven Self-Learning: The Future of Agent Cognition
      <span class="entry-hint" title="Draft">
        <svg xmlns="http://www.w3.org/2000/svg" height="20" viewBox="0 -960 960 960" fill="currentColor">
          <path
            d="M160-410v-60h300v60H160Zm0-165v-60h470v60H160Zm0-165v-60h470v60H160Zm360 580v-123l221-220q9-9 20-13t22-4q12 0 23 4.5t20 13.5l37 37q9 9 13 20t4 22q0 11-4.5 22.5T862.09-380L643-160H520Zm300-263-37-37 37 37ZM580-220h38l121-122-18-19-19-18-122 121v38Zm141-141-19-18 37 37-18-19Z" />
        </svg>
      </span>
    </h2>
  </header>
  <div class="entry-content">
    <p>In the world of artificial intelligence, we’re moving beyond simply feeding agents with information and telling them what to do. Agents shouldn’t just run on context — they should learn from it. The context window isn’t just a temporary storage for prompts; it’s a dynamic medium for meta-learning. It’s not just a scaffold, but the substrate on which the agent’s intelligence thrives.
Let’s rethink what the context in a prompt actually means. Imagine the prompt as more than just a one-off instruction. Instead, it’s a portable cognitive environment where the agent constantly remembers, reasons, reflects, and refines itself — continuously improving its performance. This is the core idea behind context-prompt-driven self-learning.
...</p>
  </div>
  <footer class="entry-footer"><span title='2025-11-15 01:42:11 +0800 CST'>November 15, 2025</span></footer>
  <a class="entry-link" aria-label="post link to Context Prompt-Driven Self-Learning: The Future of Agent Cognition" href="http://localhost:1313/posts/context_prompt_driven_self_learning/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Agent开发之上下文工程:让智能体“持续地思考”
      <span class="entry-hint" title="Draft">
        <svg xmlns="http://www.w3.org/2000/svg" height="20" viewBox="0 -960 960 960" fill="currentColor">
          <path
            d="M160-410v-60h300v60H160Zm0-165v-60h470v60H160Zm0-165v-60h470v60H160Zm360 580v-123l221-220q9-9 20-13t22-4q12 0 23 4.5t20 13.5l37 37q9 9 13 20t4 22q0 11-4.5 22.5T862.09-380L643-160H520Zm300-263-37-37 37 37ZM580-220h38l121-122-18-19-19-18-122 121v38Zm141-141-19-18 37 37-18-19Z" />
        </svg>
      </span>
    </h2>
  </header>
  <div class="entry-content">
    <p>随着 AI 系统和多 Agent 架构的发展，“上下文工程”这一概念逐渐成为设计智能体系统的核心话题。
Manus 团队在其博客文章《AI 代理的上下文工程：构建 Manus 的经验教训》中提到，在打造智能体系统的过程中，他们面临一个根本抉择：是从头训练一个端到端的智能代理模型，还是基于已有的大语言模型（LLM）构建 “上下文学习”能力？ 正是对“上下文”这一维度的深入反思，让他们最终押注于“上下文工程”（Context Engineering）。
在当下，智能体系统越来越被要求实现多轮交互、状态追踪、环境变化的感知与响应。缺乏对上下文的系统化管理，就意味着智能体容易“丢链子”：记不住上一轮、误判当前状态、无法在复杂任务中持续推进。Manus 的经验清楚地告诉我们：模型能力虽强，若缺乏结构化的上下文策略，其潜力也会大打折扣。
因此，本文将围绕 “上下文工程” 这一核心展开：从其定义到发展历程，再到一个实践示例，最终回顾关键要点并探讨未来趋势。希望你在搭建智能体系统时，能少走几步、快步收敛。
什么是上下文工程（Context Engineering） 提示词工程告诉模型“怎么问、怎么答”，而上下文工程则让模型 记住并利用过去的信息 ；前者关注单次输入，后者关注多轮连续性，两者互为补充。
可以把它想象成和朋友聊天的场景：你们聊了半个小时，你的朋友记得你之前说过的话，知道你今天的计划，也了解你的喜好。当你问“今晚吃什么”时，他就能结合之前的聊天内容，给出更贴心、更合理的建议。
上下文工程让智能体也能像这个朋友一样——不仅“听懂”当前输入，还能“记住”历史信息并合理利用：
会记住历史信息（你说过什么、做过什么） 会结合当前任务进行判断 可以管理不同任务或不同用户的上下文，避免混乱 简而言之，上下文工程就是让智能体有记忆、有判断力，不仅看现在，更懂过去和环境。
从注意力机制到上下文工程 要理解上下文工程的本质，可以从大语言模型的核心架构——Transformer 说起。 Transformer 的关键思想来自那篇里程碑式论文《Attention Is All You Need》。 自注意力机制（Self-Attention）让模型在处理每个词时，都能动态地“关注”输入序列中与之最相关的部分。模型不再是线性阅读，而是在整个上下文中分配“注意力”，由此形成理解。
从这个角度看，上下文工程其实是系统层面的注意力管理机制。 Transformer 的 attention 决定模型在输入序列内部该关注哪些 token； 而上下文工程决定模型在更高层次上该关注哪些历史、任务、环境或工具。
换句话说：
Transformer 的注意力是“微观”的，聚焦在词与词之间； 上下文工程的注意力是“宏观”的，聚焦在对话、记忆、任务和工具之间。 在复杂的智能体系统中，这种“外部注意力”尤为关键。 它帮助系统判断：什么时候该引用历史，什么时候该忽略噪声，什么时候聚焦当下。 如果说 Transformer 是微观的注意力调度器，那么上下文工程就是宏观的注意力编排师。
发展历程 GAIR-NLP 将上下文工程定位为一个涉及上下文收集、存储、管理和利用的工程过程，目标是缩小人类意图与机器理解之间的差距，并提出了上下文工程的四个发展阶段。
四阶段演进模型 时代 1.0：原始计算阶段，只能处理结构化输入，对上下文处理能力有限。人机交互成本较高，因为机器只能接受非常明确的上下文信息。 时代 2.0：以智能体为中心，出现自然语言处理、大语言模型、多模态处理和模糊信息处理能力。机器智能提升，人机交互成本下降，可以容忍更高熵（更杂乱、非结构化）的上下文信息。 时代 3.0（未来）：类人智能阶段，智能体开始理解和推理更复杂的上下文关系。 时代 4.0（未来设想）：超人智能阶段，智能体能够处理极高复杂度和不确定性的上下文，实现超人级决策和理解能力。 GAIR-NLP 指出，当前主流大语言模型（如 GPT-3 及其后续版本）具备以下 2.0 特征：
...</p>
  </div>
  <footer class="entry-footer"><span title='2025-11-12 16:21:12 +0800 CST'>November 12, 2025</span></footer>
  <a class="entry-link" aria-label="post link to Agent开发之上下文工程:让智能体“持续地思考”" href="http://localhost:1313/posts/context_engineering/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Agent development — Think in patterns, not frameworks
      <span class="entry-hint" title="Draft">
        <svg xmlns="http://www.w3.org/2000/svg" height="20" viewBox="0 -960 960 960" fill="currentColor">
          <path
            d="M160-410v-60h300v60H160Zm0-165v-60h470v60H160Zm0-165v-60h470v60H160Zm360 580v-123l221-220q9-9 20-13t22-4q12 0 23 4.5t20 13.5l37 37q9 9 13 20t4 22q0 11-4.5 22.5T862.09-380L643-160H520Zm300-263-37-37 37 37ZM580-220h38l121-122-18-19-19-18-122 121v38Zm141-141-19-18 37 37-18-19Z" />
        </svg>
      </span>
    </h2>
  </header>
  <div class="entry-content">
    <p>1. Why “off-the-shelf frameworks” are starting to fail A framework is a tool for imposing order. It helps you set boundaries amid messy requirements, makes collaboration predictable, and lets you reproduce results.
Whether it’s a business framework (OKR) or a technical framework (React, LangChain), its value is that it makes experience portable and complexity manageable.
But frameworks assume a stable problem space and well-defined goals. The moment your system operates in a high-velocity, high-uncertainty environment, that advantage falls apart:
...</p>
  </div>
  <footer class="entry-footer"><span title='2025-11-11 17:38:20 +0800 CST'>November 11, 2025</span></footer>
  <a class="entry-link" aria-label="post link to Agent development — Think in patterns, not frameworks" href="http://localhost:1313/posts/agent_development/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Building a Customer Support Agent: From Linear Flows to Expert Routing
      <span class="entry-hint" title="Draft">
        <svg xmlns="http://www.w3.org/2000/svg" height="20" viewBox="0 -960 960 960" fill="currentColor">
          <path
            d="M160-410v-60h300v60H160Zm0-165v-60h470v60H160Zm0-165v-60h470v60H160Zm360 580v-123l221-220q9-9 20-13t22-4q12 0 23 4.5t20 13.5l37 37q9 9 13 20t4 22q0 11-4.5 22.5T862.09-380L643-160H520Zm300-263-37-37 37 37ZM580-220h38l121-122-18-19-19-18-122 121v38Zm141-141-19-18 37 37-18-19Z" />
        </svg>
      </span>
    </h2>
  </header>
  <div class="entry-content">
    <p>Traditional customer service bots rely heavily on if/else rules and rigid intent-matching. The moment a user says something vague or deviates from the expected flow, the system breaks down. This is what we call “process thinking.”
In the Agent era, we shift toward “strategic thinking” — building intelligent systems that can make decisions autonomously and dynamically route conversations to the right experts. Such a system isn’t just an LLM; it’s an LLM-powered network of specialized experts.
...</p>
  </div>
  <footer class="entry-footer"><span title='2025-11-11 17:03:14 +0800 CST'>November 11, 2025</span></footer>
  <a class="entry-link" aria-label="post link to Building a Customer Support Agent: From Linear Flows to Expert Routing" href="http://localhost:1313/posts/building_a_customer_support_agent/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">My View on Agents: From Workflows to Strategic Thinking
      <span class="entry-hint" title="Draft">
        <svg xmlns="http://www.w3.org/2000/svg" height="20" viewBox="0 -960 960 960" fill="currentColor">
          <path
            d="M160-410v-60h300v60H160Zm0-165v-60h470v60H160Zm0-165v-60h470v60H160Zm360 580v-123l221-220q9-9 20-13t22-4q12 0 23 4.5t20 13.5l37 37q9 9 13 20t4 22q0 11-4.5 22.5T862.09-380L643-160H520Zm300-263-37-37 37 37ZM580-220h38l121-122-18-19-19-18-122 121v38Zm141-141-19-18 37 37-18-19Z" />
        </svg>
      </span>
    </h2>
  </header>
  <div class="entry-content">
    <p>OpenAI defines an Agent as a system that integrates model capabilities, tool interfaces, and strategies — capable of autonomously perceiving, deciding, acting, and improving its performance.
Claude, on the other hand, highlights the goal-driven and interactive nature of Agents: they not only understand and generate information, but also refine their behavior through continuous feedback.
In my view, if an LLM is the brain, then an Agent is the body that acts on behalf of that brain. An LLM is like a super-intelligent search engine and content generator — it can understand problems and produce answers, but it doesn’t act on its own. An Agent, in contrast, is like a thoughtful, hands-on assistant — it not only understands and generates, but also takes initiative and adapts based on feedback.
...</p>
  </div>
  <footer class="entry-footer"><span title='2025-11-11 14:24:50 +0800 CST'>November 11, 2025</span></footer>
  <a class="entry-link" aria-label="post link to My View on Agents: From Workflows to Strategic Thinking" href="http://localhost:1313/posts/my-view-on-agents/"></a>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="http://localhost:1313/">Thinking in Agents</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu');
    if (menu) {
        
        const scrollPosition = localStorage.getItem("menu-scroll-position");
        if (scrollPosition) {
            menu.scrollLeft = parseInt(scrollPosition, 10);
        }
        
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        const html = document.querySelector("html");
        if (html.dataset.theme === "dark") {
            html.dataset.theme = 'light';
            localStorage.setItem("pref-theme", 'light');
        } else {
            html.dataset.theme = 'dark';
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
