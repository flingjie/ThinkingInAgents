<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Posts on Thinking in Agents</title>
    <link>http://localhost:1313/posts/</link>
    <description>Recent content in Posts on Thinking in Agents</description>
    <generator>Hugo -- 0.151.0</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 11 Nov 2025 14:24:50 +0800</lastBuildDate>
    <atom:link href="http://localhost:1313/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>My View on Agents</title>
      <link>http://localhost:1313/posts/my-view-on-agents/</link>
      <pubDate>Tue, 11 Nov 2025 14:24:50 +0800</pubDate>
      <guid>http://localhost:1313/posts/my-view-on-agents/</guid>
      <description>&lt;p&gt;&lt;strong&gt;My View on Agents: From Workflows to Strategic Thinking&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;OpenAI defines an &lt;em&gt;Agent&lt;/em&gt; as a system that integrates model capabilities, tool interfaces, and strategies — capable of autonomously perceiving, deciding, acting, and improving its performance.&lt;/p&gt;
&lt;p&gt;Claude, on the other hand, highlights the goal-driven and interactive nature of Agents: they not only understand and generate information, but also refine their behavior through continuous feedback.&lt;/p&gt;
&lt;p&gt;In my view, if an LLM is the &lt;strong&gt;brain&lt;/strong&gt;, then an Agent is the &lt;strong&gt;body that acts on behalf of that brain&lt;/strong&gt;.
An LLM is like a &lt;em&gt;super-intelligent search engine and content generator&lt;/em&gt; — it can understand problems and produce answers, but it doesn’t act on its own.
An Agent, in contrast, is like a &lt;em&gt;thoughtful, hands-on assistant&lt;/em&gt; — it not only understands and generates, but also takes initiative and adapts based on feedback.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
