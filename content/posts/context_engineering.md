+++
date = '2025-11-12T16:21:12+08:00'
draft = true
title = 'Agent开发之上下文工程'
+++

随着 AI 系统和多 Agent 架构的发展，“上下文工程”这一概念逐渐成为设计智能体系统的核心话题。

Manus 团队在其博客文章《AI 代理的上下文工程：构建 Manus 的经验教训》中提到，在打造智能体系统的过程中，他们面临一个根本抉择：是从头训练一个端到端的智能代理模型，还是基于已有的大语言模型（LLM）构建 “上下文学习”能力？
正是对“上下文”这一维度的深入反思，让他们最终押注于“上下文工程”（Context Engineering）。

在当下，智能体系统越来越被要求实现多轮交互、状态追踪、环境变化的感知与响应。缺乏对上下文的系统化管理，就意味着智能体容易“丢链子”：记不住上一轮、误判当前状态、无法在复杂任务中持续推进。Manus 的经验清楚地告诉我们：模型能力虽强，若缺乏结构化的上下文策略，其潜力也会大打折扣。

因此，本文将围绕 “上下文工程” 这一核心展开：从其定义到发展历程，再到一个实践示例，最终回顾关键要点并探讨未来趋势。希望你在搭建智能体系统时，能少走几步、快步收敛。

## **什么是上下文工程（Context Engineering）**

提示词工程告诉模型“怎么问、怎么答”，而上下文工程则让模型 **记住并利用过去的信息** ；前者关注单次输入，后者关注多轮连续性，两者互为补充。

可以把它想象成和朋友聊天的场景：你们聊了半个小时，你的朋友记得你之前说过的话，知道你今天的计划，也了解你的喜好。当你问“今晚吃什么”时，他就能结合之前的聊天内容，给出更贴心、更合理的建议。

上下文工程让智能体也能像这个朋友一样——**不仅“听懂”当前输入，还能“记住”历史信息并合理利用**：

- 会记住历史信息（你说过什么、做过什么）
- 会结合当前任务进行判断
- 可以管理不同任务或不同用户的上下文，避免混乱

简而言之，上下文工程就是让智能体**有记忆、有判断力**，不仅看现在，更懂过去和环境。

## **从注意力机制到上下文工程**

要理解上下文工程的本质，可以从大语言模型的核心架构——**Transformer** 说起。
Transformer 的关键思想来自那篇里程碑式论文《Attention Is All You Need》。
自注意力机制（Self-Attention）让模型在处理每个词时，都能动态地“关注”输入序列中与之最相关的部分。模型不再是线性阅读，而是在整个上下文中分配“注意力”，由此形成理解。

从这个角度看，**上下文工程其实是系统层面的注意力管理机制**。
Transformer 的 attention 决定模型在输入序列内部该关注哪些 token；
而上下文工程决定模型在更高层次上该关注哪些**历史、任务、环境或工具**。

换句话说：

- Transformer 的注意力是“微观”的，聚焦在词与词之间；
- 上下文工程的注意力是“宏观”的，聚焦在对话、记忆、任务和工具之间。

在复杂的智能体系统中，这种“外部注意力”尤为关键。
它帮助系统判断：什么时候该引用历史，什么时候该忽略噪声，什么时候聚焦当下。
如果说 Transformer 是**微观的注意力调度器**，那么上下文工程就是**宏观的注意力编排师**。

## **发展历程**

GAIR-NLP 将上下文工程定位为一个涉及**上下文收集、存储、管理和利用**的工程过程，目标是缩小人类意图与机器理解之间的差距，并提出了上下文工程的四个发展阶段。

### **四阶段演进模型**

- **时代 1.0**：原始计算阶段，只能处理结构化输入，对上下文处理能力有限。人机交互成本较高，因为机器只能接受非常明确的上下文信息。
- **时代 2.0**：以智能体为中心，出现自然语言处理、大语言模型、多模态处理和模糊信息处理能力。机器智能提升，人机交互成本下降，可以容忍更高熵（更杂乱、非结构化）的上下文信息。
- **时代 3.0（未来）**：类人智能阶段，智能体开始理解和推理更复杂的上下文关系。
- **时代 4.0（未来设想）**：超人智能阶段，智能体能够处理极高复杂度和不确定性的上下文，实现超人级决策和理解能力。

![this is a image](/images/context_overview.png)
GAIR-NLP 指出，当前主流大语言模型（如 GPT-3 及其后续版本）具备以下 2.0 特征：

- 能处理非结构化、含糊的输入
- 能进行主动推理
- 上下文不仅是“输入信息”，更是“指令或指导”

这些特征标志着我们已经进入上下文工程 2.0 阶段——智能体不仅能理解即时输入，还能利用上下文做出连续、智能的决策。

## **实践与示例**

下面的示例演示如何用 **LangChain** 构建一个简单的上下文工程系统，模拟“订机票”的多轮对话场景，让模型能够记住历史信息并结合当前需求给出合理回复。

```python
from langchain.vectorstores import FAISS
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.chat_models import ChatOpenAI
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory

# --- 1. 初始化 LLM 和向量存储 ---
embeddings = OpenAIEmbeddings()
vector_store = FAISS(embeddings.embed_query, dimension=1536)  # 将文本转为向量

# --- 2. 设置会话记忆 ---
memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)

# --- 3. 创建 LLM 对话链 ---
llm = ChatOpenAI(model_name="gpt-4", temperature=0.7)
conversation_chain = ConversationalRetrievalChain.from_llm(
    llm=llm,
    retriever=vector_store.as_retriever(search_kwargs={"k": 5}),  # 检索相似历史信息
    memory=memory,
)

# --- 4. 模拟多轮对话 ---
user_id = "user_a"
user_inputs = [
    "我想订明天去北京的机票",
    "帮我选最便宜的航班",
    "希望上午出发"
]

for user_input in user_inputs:
    response = conversation_chain.run(user_input)
    print("模型回复:", response)

# --- 5. 新输入结合上下文生成回复 ---
latest_input = "请帮我确认航班信息"
response = conversation_chain.run(latest_input)
print("\n最新回复:", response)
```

---

### **生成回复过程详细解说**

在上面的代码中，当你输入一条信息时，系统生成回复的流程大致如下：

1. **用户输入接收**

   - 用户发送请求（如“我想订明天去北京的机票”）。
   - 系统将输入传递给 `ConversationalRetrievalChain`。

2. **上下文检索**

   - **Memory 检查历史对话**：`ConversationBufferMemory` 会返回当前用户之前的对话内容。
   - **向量检索（FAISS）**：将用户输入转为向量，并检索与之最相似的历史上下文（k=5 条最相关信息）。
   - 检索出的上下文会作为附加信息输入给 LLM。

3. **生成提示（Prompt Construction）**

   - `ConversationalRetrievalChain` 会将当前输入 + 历史上下文 + 检索到的相似信息拼接成一个完整的提示（prompt）。
   - 例如：

     ```
     历史对话：
     用户：我想订明天去北京的机票
     系统：好的，请问希望哪家航空公司？

     当前输入：
     帮我选最便宜的航班

     请根据以上信息给出建议。
     ```

4. **模型生成回复**

   - LLM 接收到完整提示后，通过自身的注意力机制（attention）整合历史上下文和当前输入，生成符合上下文的回答。
   - 此时模型“记得”用户的之前需求，也能考虑新的约束条件。

5. **更新记忆**

   - 系统将这轮对话加入 `ConversationBufferMemory`。
   - 下一轮对话时，模型可以直接访问这条记录，从而实现连续、多轮对话。

6. **返回给用户**

   - 系统输出生成的文本，作为最终回复。
   - 如果用户输入进一步要求（如“请帮我确认航班信息”），流程重复，但上下文会随着对话累积而不断丰富，生成的回复会更加精准和个性化。

### **流程优势**

- **多轮连续性**：模型不仅处理当前输入，还能结合历史对话。
- **信息回溯**：通过向量检索，跨会话也能调用相关历史信息。
- **个性化**：结合用户偏好和历史行为生成更贴近需求的回答。
- **易扩展**：可以支持多用户、多任务甚至跨 Agent 的上下文管理。

## **总结与展望**

本文从定义、发展、实践示例到案例分析，全面梳理了上下文工程在智能体系统中的应用。核心要点包括：

- 上下文工程不仅是状态管理，而是智能化、任务导向的上下文管理
- 动态和智能上下文管理是未来趋势
- 实践中需注意上下文膨胀、隔离及可扩展性

未来，随着 LLM 和多 Agent 系统的发展，上下文工程将成为智能体系统设计的核心能力。通过合理设计和优化上下文策略，智能体能够更精准、更连贯地理解和执行任务，从而实现更高水平的智能交互。
