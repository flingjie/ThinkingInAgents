+++
date = '2025-12-02T09:46:48+08:00'
draft = true
title = '一次Agent项目失利手记'
+++

今年上半年，我接手了一个让我心潮澎湃的项目：为一家业务飞速扩张的公司构建一套内部智能 Agent 系统。我们的愿景很宏大——希望 Agent 能自主处理部分工单、高效汇总业务信息，甚至智能触发内部流程。那时候，AI 圈子正热得发烫，人人都在谈 Agent，我也觉得自己站在了风口浪尖。

然而，现实却狠狠地泼了一盆冷水。项目非但没有跑出预期的曲线，反而像一连串的“技术地雷”，接二连三地爆炸。

直到项目被紧急叫停的那一刻，我才恍然大悟：许多看似纯粹的技术难题，实则根植于我们对工程化理念的忽视。

这篇文字，是我对那段经历的一次痛彻心扉的回顾。

### **一、项目开局：一切顺利得让人不安**

说实话，项目的启动阶段顺利得有些过分。

我们迅速选用了当时最新的大模型，搭建了一个简洁的对话界面，并初步绑定了几项核心业务工具。仅仅两周时间，一个像模像样的 Demo 就成功跑通了几个典型的工单处理流程。

领导和客户看了 Demo，赞不绝口。那一刻，我心头升起一股傲气，觉得凭我们团队的能力，这次 Agent 落地定能一帆风顺。

然而，正是这种盲目的乐观，为后来的急转直下埋下了伏笔。当我们将系统接入真实的业务数据环境时，好戏才真正开场。

### **二、第一次“撞墙”：Agent 在信息洪流中迷失了方向**

灰度上线的第一天，系统刚运行没几个小时，我们后台的监控告警就开始疯狂闪烁。

原因听起来有些啼笑皆非：Agent 本应根据用户输入的关键词，准确判断工单是售后问题还是物流咨询。但在某些特定场景下，它会错误地将工单识别为“未知类型”，随即陷入一个“怪圈”——反复调用同一个查询工具，频率之高，一度让我们以为系统正遭受 DDoS 攻击。

那天晚上，我盯着日志，看到怀疑人生：

> 调用：工单查询 → 发现没结果 → 尝试改写问题 → 再次工单查询 → 仍然没结果 → 又一次改写...

它就像一个被困在房间里的机器人，固执地、一遍又一遍地敲击着同一扇根本打不开的门。我们后来形象地称之为“围墙式死循环”。

### **三、愈演愈烈：Agent 开始“胡乱发号施令”**

进入第二周，一个更为棘手的事故发生了。

在某些复杂的边缘场景下，Agent 再次做出了错误的选择，这次它误选了一个用于触发“审批提醒”的工具，导致两个毫不相关的部门突然收到了莫名其妙的审批通知。

谢天谢地，这只是一个低风险的提醒流程，没有造成真正的生产事故，但却在公司内部引起了不小的混乱。客户那边来电话质询时，我脑子里的第一反应不是恐慌，而是茫然：“怎么又是 Agent？我们不是刚修好了那个死循环吗？”

深入排查后，我们才摸清了症结：

- **工具命名风格混乱：** 缺乏统一的规范。
- **返回数据结构不一致：** 各个工具的输出五花八门。
- **调用约定模糊：** 不同的工具调用方式差异大。

当工具数量从最初的 8 个迅速膨胀到 20 多个时，Agent 的内部决策逻辑彻底陷入了混乱。那一刻我才醍醐灌顶：**我们根本没有建立起一套健全的“工具治理体系”！**

回想起来，将几十个未经规范和约束的工具一股脑地扔给一个 AI 智能体自由调用，这和放任一个不了解业务的实习生随意操作上百个内部 API 几乎没有区别——甚至可能更加危险。

### **四、团队的疲惫：信心开始动摇**

有一段时间，我们团队几乎每天都在为新的边缘案例焦头烂额，而且越到后期，修补的难度越大。

前端同事抱怨 Agent 的行为模式难以预测，导致界面交互频繁出错。后端同事则深陷于错综复杂的调用日志，感觉像在迷宫里探索。而最直接的业务方，客户，也反馈体验越来越“怪异”。

在项目组的会议上，我们常常听到一句令人扎心，却又无法反驳的话：

> “你们能不能把它弄得稳定一点？”

这句话像一根针，直插我们内心最脆弱的地方。

### **五、项目暂停：压垮我们的不是技术瓶颈，而是系统性缺失**

项目正式被叫停那天，我与项目负责人进行了一次深谈。他皱着眉问我：“核心问题到底出在哪？你们不是说大模型本身没问题吗？”

我反复思索，给出的答案是：

- 并非模型能力不足。
- 并非代码质量不高。
- 并非工具库不够丰富。

我们最大的症结，在于**项目前期对工程化考量的严重不足**：

- 缺乏一套明确的工具规范。
- 没有划定清晰的能力边界。
- 未曾建立稳健的稳定性策略。
- 遗漏了严谨的验证路径。
- 缺失了有效的风险回退机制。

简单来说：**我们对 AI 能力的信任，超越了对工程严谨性的重视。**

### **六、涅槃重生：两个月后，另一个项目成功破茧**

项目虽然暂停了，但我们并没有放弃。团队痛定思痛，决定从根本上重构架构和流程：

1.  **重建工具治理体系**
    我们投入大量精力，统一了：

    - **工具的输入输出结构**，确保数据流转清晰无误。
    - **工具分类与能力标签**，让 Agent 能更智能地选择合适工具。
    - **工具版本与变更记录**，避免意外的兼容性问题。
    - **安全边界与权限隔离**，严格控制 Agent 对内部系统的访问。
      现在，Agent 再也不会在无关工具之间胡乱“迷路”了。

2.  **将 LLM 视为概率系统来对待**
    我们清醒地认识到 AI 的非确定性，并在设计中加入了：

    - **严格的输入输出校验**，过滤不合规数据。
    - **行为约束**，为 Agent 划定行动红线。
    - **规则化兜底机制**，在 AI 决策失败时提供确定性路径。
    - **回退策略与人工确认点**，确保关键流程万无一失。
      模型不再是“想怎么做就怎么做”，而是被纳入一个可控的框架。

3.  **分阶段稳健推进**
    我们彻底告别了“一键接全链路”的激进模式，转而采取小步快跑、逐步验证的策略：
    - **先确保单个任务的闭环稳定运行。**
    - **再在一个部门内部进行灰度验证。**
    - **工具能力逐个扩容，每次都进行充分测试。**
    - **最后才考虑跨部门和全流程的集成。**

这套全新的方法论，后来在公司的另一个业务线成功落地。

数据是最有力的证明：

- 工具错误率从 24%直线下降到**3%**。
- 通过能力标签优化，工具调用冗余减少了**40%**。
- Agent 的决策稳定性有了**显著提升**。
- 在多部门灰度测试中，连续三周**未出现任何重大事故**。

那一刻，我才真正长舒了一口气。两次项目，底层技术基本相同，**但工程纪律和边界控制的改进，却带来了天壤之别。**

### **七、写在最后：失败有时更像一面明镜**

这次失败的项目，对我个人的职业生涯影响深远。

它让我深刻意识到：

- Agent 所谓的“聪明”，有时只是一种表象。
- 系统的稳定性，根植于扎实的工程实践，而非模型能力的无限拔高。
- 对工具缺乏治理，最终必然导致灾难性的后果。
- Demo 永远是最容易迷惑人的东西，它无法替代真实场景的严酷检验。
- AI 并非万能灵药，真正的系统基石始终是工程框架和流程。

我们常说“大模型技术升级带来了颠覆性变化”，但这次经历告诉我：**真正的成功，往往来源于那些看似“无聊”、琐碎，甚至不那么“AI”的工程细节和严谨管理。**

希望这份带着痛楚的反思，能为你正在进行的 Agent 项目提供一点借鉴。如果你也在探索这条道路，愿你少走一些我曾经踩过的弯路。
